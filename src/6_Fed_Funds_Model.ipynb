{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate, StratifiedKFold, learning_curve, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, plot_confusion_matrix, roc_auc_score, roc_curve, auc, plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247, 78)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>next_rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>Taylor</th>\n",
       "      <th>Balanced</th>\n",
       "      <th>Inertia</th>\n",
       "      <th>Taylor-Rate</th>\n",
       "      <th>Balanced-Rate</th>\n",
       "      <th>Inertia-Rate</th>\n",
       "      <th>Taylor_diff</th>\n",
       "      <th>Balanced_diff</th>\n",
       "      <th>Inertia_diff</th>\n",
       "      <th>next_decision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_meeting</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-27</th>\n",
       "      <td>3581.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.052646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-17</th>\n",
       "      <td>3216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.803908</td>\n",
       "      <td>...</td>\n",
       "      <td>1.319339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.319339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-28</th>\n",
       "      <td>2298.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.286692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-16</th>\n",
       "      <td>2939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782446</td>\n",
       "      <td>...</td>\n",
       "      <td>4.239942</td>\n",
       "      <td>2.825180</td>\n",
       "      <td>-0.423777</td>\n",
       "      <td>4.239942</td>\n",
       "      <td>2.825180</td>\n",
       "      <td>-0.423777</td>\n",
       "      <td>2.953250</td>\n",
       "      <td>2.825180</td>\n",
       "      <td>-0.423777</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28</th>\n",
       "      <td>2716.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>0.185160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801772</td>\n",
       "      <td>...</td>\n",
       "      <td>4.749861</td>\n",
       "      <td>3.335099</td>\n",
       "      <td>-0.500265</td>\n",
       "      <td>4.749861</td>\n",
       "      <td>3.335099</td>\n",
       "      <td>-0.500265</td>\n",
       "      <td>0.509919</td>\n",
       "      <td>0.509919</td>\n",
       "      <td>-0.076488</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_count  next_rate    0         1    2         3         4  \\\n",
       "next_meeting                                                                  \n",
       "2021-01-27        3581.0        0.0  0.0  0.000000  0.0  0.000000  0.192184   \n",
       "2021-03-17        3216.0        0.0  0.0  0.000000  0.0  0.000000  0.185558   \n",
       "2021-04-28        2298.5        0.0  0.0  0.000000  0.0  0.000000  0.191281   \n",
       "2021-06-16        2939.0        0.0  0.0  0.007824  0.0  0.000000  0.204571   \n",
       "2021-07-28        2716.5        0.0  0.0  0.000000  0.0  0.007714  0.185160   \n",
       "\n",
       "                5         6         7  ...    Taylor  Balanced   Inertia  \\\n",
       "next_meeting                           ...                                 \n",
       "2021-01-27    0.0  0.000000  0.802176  ...  0.802493  0.000000  0.000000   \n",
       "2021-03-17    0.0  0.005331  0.803908  ...  1.319339  0.000000  0.000000   \n",
       "2021-04-28    0.0  0.000000  0.803392  ...  1.286692  0.000000  0.000000   \n",
       "2021-06-16    0.0  0.000000  0.782446  ...  4.239942  2.825180 -0.423777   \n",
       "2021-07-28    0.0  0.000000  0.801772  ...  4.749861  3.335099 -0.500265   \n",
       "\n",
       "              Taylor-Rate  Balanced-Rate  Inertia-Rate  Taylor_diff  \\\n",
       "next_meeting                                                          \n",
       "2021-01-27       0.802493       0.000000      0.000000    -0.052646   \n",
       "2021-03-17       1.319339       0.000000      0.000000     0.516847   \n",
       "2021-04-28       1.286692       0.000000      0.000000    -0.032647   \n",
       "2021-06-16       4.239942       2.825180     -0.423777     2.953250   \n",
       "2021-07-28       4.749861       3.335099     -0.500265     0.509919   \n",
       "\n",
       "              Balanced_diff  Inertia_diff  next_decision  \n",
       "next_meeting                                              \n",
       "2021-01-27         0.000000      0.000000            2.0  \n",
       "2021-03-17         0.000000      0.000000            2.0  \n",
       "2021-04-28         0.000000      0.000000            2.0  \n",
       "2021-06-16         2.825180     -0.423777            2.0  \n",
       "2021-07-28         0.509919     -0.076488            2.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "file = open('../data/final_fed_data.pickle', 'rb')\n",
    "data = pd.read_pickle(file)\n",
    "file.close()\n",
    "\n",
    "print(data.shape)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unscheduled</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confcall</th>\n",
       "      <th>Rate</th>\n",
       "      <th>RateDiff</th>\n",
       "      <th>RateDecision</th>\n",
       "      <th>ChairPerson</th>\n",
       "      <th>RateChanged</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-16</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            unscheduled  forecast  confcall  Rate  RateDiff  RateDecision  \\\n",
       "date                                                                        \n",
       "2021-06-16        False      True     False   0.0       0.0             0   \n",
       "2021-07-28        False     False     False   0.0       0.0             0   \n",
       "2021-09-22        False      True     False   0.0       0.0             0   \n",
       "2021-11-03        False     False     False   0.0       0.0             0   \n",
       "2021-12-15        False      True     False   0.0       0.0             0   \n",
       "\n",
       "           ChairPerson  RateChanged  \n",
       "date                                 \n",
       "2021-06-16         NaN            0  \n",
       "2021-07-28         NaN            0  \n",
       "2021-09-22         NaN            0  \n",
       "2021-11-03         NaN            0  \n",
       "2021-12-15         NaN            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fed calendar\n",
    "file = open('../data/preprocessed/fomc_calendar.pickle', 'rb')\n",
    "fomc_cal = pd.read_pickle(file)\n",
    "file.close()\n",
    "\n",
    "print(fomc_cal.shape)\n",
    "fomc_cal.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model features\n",
    "feature_columns = ['GDP_diff_prev', 'GDP_diff_year', 'GDPPOT_diff_prev', 'GDPPOT_diff_year',\n",
    "                  'PCE_diff_prev', 'PCE_diff_year', 'CPI_diff_prev', 'CPI_diff_year', \n",
    "                  'Unemp_value', 'Unemp_diff_prev', 'Unemp_diff_year',\n",
    "                  'Employ_value', 'Employ_diff_prev', 'Employ_diff_year',\n",
    "                  'PMI_value', 'PMI_diff_prev', 'PMI_diff_year', \n",
    "                  'Rsales_diff_prev', 'Hsales_diff_prev', 'Hsales_diff_year',\n",
    "                  'Taylor-Rate', 'Balanced-Rate', 'Inertia-Rate', 'Taylor_diff', 'Balanced_diff', 'Inertia_diff',\n",
    "                  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17\n",
    "                  ]\n",
    "\n",
    "X = data.dropna(subset = ['next_decision'])\n",
    "X = X[feature_columns]\n",
    "X = X.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(X.columns)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(data['next_decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "rand_seed = 42\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = random.randint(0,1000), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=2, n=134 (68.020%)\n",
      "Class=3, n=31 (15.736%)\n",
      "Class=1, n=32 (16.244%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize distribution\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    \n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_euclidean_distances' from 'sklearn.metrics.pairwise' (/Users/akalodzitsa/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# oversample using SMOTE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# reference: https://machinelearningmastery.com/multi-class-imbalanced-classification/\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      5\u001b[0m oversample \u001b[38;5;241m=\u001b[39m SMOTE()\n\u001b[1;32m      6\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m oversample\u001b[38;5;241m.\u001b[39mfit_resample(x_train, y_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/__init__.py:52\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combine\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensemble\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/combine/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/combine/_smote_enn.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/over_sampling/__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BorderlineSMOTE\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/over_sampling/_smote/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEN\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTENC\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BorderlineSMOTE\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/over_sampling/_smote/cluster.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MiniBatchKMeans\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_distances\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.cluster` module gathers popular unsupervised clustering\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03malgorithms.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spectral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spectral_clustering, SpectralClustering\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mean_shift\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_shift, MeanShift, estimate_bandwidth, get_bin_seeds\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m affinity_propagation, AffinityPropagation\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_spectral.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kneighbors_graph, NearestNeighbors\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spectral_embedding\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kmeans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m k_means\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiscretize\u001b[39m(\n\u001b[1;32m     22\u001b[0m     vectors, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_svd_restarts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, n_iter_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     23\u001b[0m ):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"Search for a partition matrix which is closest to the eigenvector embedding.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    This implementation was proposed in [1]_.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, ClusterMixin, TransformerMixin\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m euclidean_distances\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _euclidean_distances\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m row_norms, stable_cumsum\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m threadpool_limits\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_euclidean_distances' from 'sklearn.metrics.pairwise' (/Users/akalodzitsa/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py)"
     ]
    }
   ],
   "source": [
    "# oversample using SMOTE\n",
    "# reference: https://machinelearningmastery.com/multi-class-imbalanced-classification/\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "# summarize distribution\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    \n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /Users/akalodzitsa/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/akalodzitsa/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/akalodzitsa/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.20.3)\n",
      "Collecting scikit-learn>=1.0.1\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/akalodzitsa/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed imbalanced-learn-0.9.0 imblearn-0.0 scikit-learn-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "# Set logger\n",
    "logger = logging.getLogger('mylogger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "timestamp = time.strftime(\"%Y.%m.%d_%H.%M.%S\", time.localtime())\n",
    "fh = logging.FileHandler('log_model.txt')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s] ## %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# Use Stratified KFold Cross Validation\n",
    "n_fold = 7\n",
    "kfold = StratifiedKFold(n_splits=n_fold)\n",
    "kfold\n",
    "# Define metrics\n",
    "# Here, use F1 Macro to evaluate the model.\n",
    "def metric(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return acc, f1\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy', 'F1': 'f1_macro'}\n",
    "refit = 'F1'\n",
    "\n",
    "def train_grid_search(estimator, param_grid, scoring, refit, cv=5, verbose=1, plot=True):\n",
    "    model = GridSearchCV(estimator, param_grid=param_grid, cv=cv, scoring=scoring, verbose=verbose, \n",
    "                         refit=refit, n_jobs=-1, return_train_score=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    results = model.cv_results_\n",
    "    best_estimator = model.best_estimator_\n",
    "    train_scores = results['mean_train_' + refit]\n",
    "    test_scores = results['mean_test_' + refit]\n",
    "    train_time = results['mean_fit_time']\n",
    "    \n",
    "    print(\"Best Score: \", model.best_score_)\n",
    "    print(\"Best Param: \", model.best_params_)\n",
    "    \n",
    "    pred_train = best_estimator.predict(x_train)\n",
    "    pred_test = best_estimator.predict(x_test)\n",
    "\n",
    "    acc, f1 = metric(y_train, pred_train)\n",
    "    logger.info('Training - acc: %.8f, f1: %.8f' % (acc, f1))\n",
    "    acc, f1 = metric(y_test, pred_test)\n",
    "    logger.info('Test - acc: %.8f, f1: %.8f' % (acc, f1))\n",
    "        \n",
    "    if plot:\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        fig.suptitle(\"GridSearchCV Result\", fontsize=20)\n",
    "        \n",
    "        ### First plot ###\n",
    "        ax1.plot(train_scores, test_scores, 'bo')\n",
    "        ax1.set_title(\"Train Score v.s. Test Score\", fontsize=16)\n",
    "        ax1.set_xlabel(\"Train Score\")\n",
    "        ax1.set_ylabel(\"Test Score\")\n",
    "        ax1.set_xlim(0, 1)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        ### Second plot ###\n",
    "        x_param = list(param_grid.keys())[0]\n",
    "        x_param_min = np.min(list(param_grid.values())[0])\n",
    "        x_param_max = np.max(list(param_grid.values())[0])\n",
    "\n",
    "        ax2.set_title(\"Score over the first param\", fontsize=16)\n",
    "        ax2.set_xlabel(x_param)\n",
    "        ax2.set_ylabel(\"Score\")\n",
    "        ax2.set_xlim(x_param_min, x_param_max)\n",
    "        ax2.set_ylim(0, 1)\n",
    "\n",
    "        # Get the regular numpy array from the MaskedArray\n",
    "        X_axis = np.array(results['param_' + x_param].data, dtype=float)\n",
    "\n",
    "        for scorer, color in zip(sorted(scoring), ['r', 'g']):\n",
    "            for sample, style in (('train', '--'), ('test', '-')):\n",
    "                sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "                sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "                ax2.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                                sample_score_mean + sample_score_std,\n",
    "                                alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "                ax2.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                        alpha=1 if sample == 'test' else 0.7,\n",
    "                        label=\"%s (%s)\" % (scorer, sample.capitalize()))\n",
    "\n",
    "            best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "            best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "            # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "            ax2.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "                    linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "            # Annotate the best score for that scorer\n",
    "            ax2.annotate(\"%0.2f\" % best_score,\n",
    "                        (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "        ax2.legend(loc=\"best\")\n",
    "        ax2.grid(False)\n",
    "        \n",
    "        ### Third plot (Learning Curve) ###\n",
    "        # Calculate learning curve (Accuracy)\n",
    "        lc_acc_train_sizes, lc_acc_train_scores, lc_acc_test_scores = learning_curve(\n",
    "            best_estimator, x_train, y_train, cv=kfold, n_jobs=-1, scoring=scoring['Accuracy'], \n",
    "            train_sizes=np.linspace(.1, 1.0, 5))\n",
    "        lc_acc_train_mean = np.mean(lc_acc_train_scores, axis=1)\n",
    "        lc_acc_train_std = np.std(lc_acc_train_scores, axis=1)\n",
    "        lc_acc_test_mean = np.mean(lc_acc_test_scores, axis=1)\n",
    "        lc_acc_test_std = np.std(lc_acc_test_scores, axis=1)\n",
    "        \n",
    "        # Calculate learning curve (F1 Score)\n",
    "        lc_f1_train_sizes, lc_f1_train_scores, lc_f1_test_scores = learning_curve(\n",
    "            best_estimator, x_train, y_train, cv=kfold, n_jobs=-1, scoring=scoring['F1'], \n",
    "            train_sizes=np.linspace(.1, 1.0, 5))\n",
    "        lc_f1_train_mean = np.mean(lc_f1_train_scores, axis=1)\n",
    "        lc_f1_train_std = np.std(lc_f1_train_scores, axis=1)\n",
    "        lc_f1_test_mean = np.mean(lc_f1_test_scores, axis=1)\n",
    "        lc_f1_test_std = np.std(lc_f1_test_scores, axis=1)\n",
    "        \n",
    "        ax3.set_title(\"Learning Curve\", fontsize=16)\n",
    "        ax3.set_xlabel(\"Training examples\")\n",
    "        ax3.set_ylabel(\"Score\")\n",
    "\n",
    "        # Plot learning curve (Accuracy)\n",
    "        ax3.fill_between(lc_acc_train_sizes, \n",
    "                         lc_acc_train_mean - lc_acc_train_std,\n",
    "                         lc_acc_train_mean + lc_acc_train_std, alpha=0.1, color=\"r\")\n",
    "        ax3.fill_between(lc_acc_train_sizes, \n",
    "                         lc_acc_test_mean - lc_acc_test_std,\n",
    "                         lc_acc_test_mean + lc_acc_test_std, alpha=0.1, color=\"r\")\n",
    "        ax3.plot(lc_acc_train_sizes, lc_acc_train_mean, 'o--', color=\"r\",\n",
    "                 label=\"Accuracy (Train)\")\n",
    "        ax3.plot(lc_acc_train_sizes, lc_acc_test_mean, 'o-', color=\"r\",\n",
    "                 label=\"Accuracy (Test)\")\n",
    "        \n",
    "        # Plot learning curve (F1 Score)\n",
    "        ax3.fill_between(lc_f1_train_sizes, \n",
    "                         lc_f1_train_mean - lc_f1_train_std,\n",
    "                         lc_f1_train_mean + lc_f1_train_std, alpha=0.1, color=\"g\")\n",
    "        ax3.fill_between(lc_f1_train_sizes, \n",
    "                         lc_f1_test_mean - lc_f1_test_std,\n",
    "                         lc_f1_test_mean + lc_f1_test_std, alpha=0.1, color=\"g\")\n",
    "        ax3.plot(lc_f1_train_sizes, lc_f1_train_mean, 'o--', color=\"g\",\n",
    "                 label=\"F1 (Train)\")\n",
    "        ax3.plot(lc_f1_train_sizes, lc_f1_test_mean, 'o-', color=\"g\",\n",
    "                 label=\"F1 (Test)\")\n",
    "\n",
    "        ax3.legend(loc=\"best\")\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.show()\n",
    "        \n",
    "        ### Confusion Matrix ###\n",
    "        class_names = ['Lower', 'Hold', 'Raise']\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(\"Confusion Matrix\", fontsize=20)\n",
    "        \n",
    "        plot_confusion_matrix(best_estimator, x_train, y_train, display_labels=class_names, \n",
    "                              cmap=plt.cm.Blues, normalize=None, ax=ax1)\n",
    "        ax1.set_title(\"Train Data: Actual Count\")\n",
    "        ax1.grid(False)\n",
    "        \n",
    "        plot_confusion_matrix(best_estimator, x_train, y_train, display_labels=class_names, \n",
    "                              cmap=plt.cm.Blues, normalize='all', ax=ax2)\n",
    "        ax2.set_title=(\"Train Data: Normalized\")\n",
    "        ax2.grid(False)\n",
    "        \n",
    "        plot_confusion_matrix(best_estimator, x_test, y_test, display_labels=class_names, \n",
    "                              cmap=plt.cm.Blues, normalize=None, ax=ax3)\n",
    "        ax3.set_title=(\"Test Data: Actual Count\")\n",
    "        ax3.grid(False)\n",
    "        \n",
    "        plot_confusion_matrix(best_estimator, x_test, y_test, display_labels=class_names, \n",
    "                              cmap=plt.cm.Blues, normalize='all', ax=ax4)\n",
    "        ax4.set_title(\"Test Data: Normalized\")\n",
    "        ax4.grid(False)\n",
    "        \n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.show()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Perform Grid Search\n",
    "param_grid = {'n_estimators': np.linspace(1, 500, 50, dtype=int),\n",
    "              'min_samples_split': [5],\n",
    "              'min_samples_leaf': [10],\n",
    "              'max_features': [8],\n",
    "              'max_depth': [None],\n",
    "              'criterion': ['gini'],\n",
    "              'bootstrap': [False]}\n",
    "\n",
    "ext_model = train_grid_search(rf_clf, param_grid, scoring, refit, cv=kfold, verbose=1, plot=True)\n",
    "ext_best = ext_model.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(bootstrap = False, criterion = 'gini', \n",
    "                                  max_depth = None, max_features = 8, min_samples_leaf = 10, \n",
    "                                  min_samples_split = 5, n_estimators = 357)\n",
    "\n",
    "\n",
    "rf_model = rf_model.fit(x_train, y_train)\n",
    "rf_predictions = rf_model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "scores = rf_model.score(x_test, y_test)\n",
    "print('Accuracy: ', scores)\n",
    "\n",
    "# roc \n",
    "print('ROC score: ', roc_auc_score(y_test, rf_model.predict_proba(x_test), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, 'o', color='orange', label = \"Actual\")\n",
    "plt.plot(rf_predictions,  'x', color='blue', label = \"Prediction\")\n",
    "plt.title('1-Step Ahead')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion Matrix ###\n",
    "class_names = ['Lower', 'Hold', 'Raise']\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(\"Confusion Matrix\", fontsize=20)\n",
    "\n",
    "plot_confusion_matrix(rf_model, x_train, y_train, display_labels=class_names, \n",
    "                      cmap=plt.cm.Blues, normalize=None, ax=ax1)\n",
    "ax1.set_title(\"Train Data: Actual Count\")\n",
    "ax1.grid(False)\n",
    "\n",
    "plot_confusion_matrix(rf_model, x_train, y_train, display_labels=class_names, \n",
    "                      cmap=plt.cm.Blues, normalize='all', ax=ax2)\n",
    "ax2.set_title=(\"Train Data: Normalized\")\n",
    "ax2.grid(False)\n",
    "\n",
    "plot_confusion_matrix(rf_model, x_test, y_test, display_labels=class_names, \n",
    "                      cmap=plt.cm.Blues, normalize=None, ax=ax3)\n",
    "ax3.set_title=(\"Test Data: Actual Count\")\n",
    "ax3.grid(False)\n",
    "\n",
    "plot_confusion_matrix(rf_model, x_test, y_test, display_labels=class_names, \n",
    "                      cmap=plt.cm.Blues, normalize='all', ax=ax4)\n",
    "ax4.set_title(\"Test Data: Normalized\")\n",
    "ax4.grid(False)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get numerical feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(rf_model.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(data.index, data.Inertia_diff, label = 'Inertia Rule')\n",
    "#plt.plot(data.index, np.log(data.PMI_value), label = 'PMI')\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=80)\n",
    "\n",
    "plt.plot(data.index, data.next_rate, 'o', alpha = 0.5, label = 'Next Rate Decision')\n",
    "plt.plot(data.index, data[6], 'x', label = 'Topic 6')\n",
    "plt.plot(data.index, data[5], 'x', label = 'Topic 5')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(rf_model, open('../data/final_fed_model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Step Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['GDP_diff_prev', 'GDP_diff_year', 'GDPPOT_diff_prev',\n",
    "                   'GDPPOT_diff_year', 'PCE_diff_prev', 'PCE_diff_year',\n",
    "                   'CPI_diff_prev', 'CPI_diff_year', 'Unemp_value',\n",
    "                   'Unemp_diff_prev', 'Unemp_diff_year', 'Employ_value',\n",
    "                   'Employ_diff_prev', 'Employ_diff_year', 'PMI_value',\n",
    "                   'PMI_diff_prev', 'PMI_diff_year', 'Rsales_diff_prev',\n",
    "                   'Hsales_diff_prev', 'Hsales_diff_year', 'Taylor-Rate',\n",
    "                   'Balanced-Rate', 'Inertia-Rate',  'Taylor_diff',\n",
    "                   'Balanced_diff', 'Inertia_diff', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "future_pred = []\n",
    "\n",
    "def multi_step_pred(y_col, n_steps):\n",
    "    for step in n_steps:\n",
    "        col_name = str(y_col) + '_' + str(step)\n",
    "        data[col_name] = data['RateDecision'].shift(step)\n",
    "        df = data.dropna(subset = [col_name])\n",
    "\n",
    "        X = df[feature_columns]\n",
    "        X = X.dropna(axis='columns')\n",
    "        feature_list = list(X.columns)\n",
    "        X = np.array(X)\n",
    "        y = np.array(df[col_name])\n",
    "\n",
    "        # set random seed\n",
    "        random.seed(42)\n",
    "        np.random.seed(42)\n",
    "        rand_seed = 42\n",
    "\n",
    "        # split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = random.randint(0,1000), shuffle = False)\n",
    "        x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "\n",
    "        rf_model = RandomForestClassifier(bootstrap = False, criterion = 'gini', \n",
    "                                      max_depth = None, max_features = 8, min_samples_leaf = 10, \n",
    "                                      min_samples_split = 5, n_estimators = 500)\n",
    "\n",
    "        rf_model = rf_model.fit(x_train, y_train)\n",
    "        rf_predictions = rf_model.predict(x_test)\n",
    "\n",
    "        # performance\n",
    "        scores = rf_model.score(x_test, y_test)\n",
    "        print(str(step) + '-Ahead Accuracy: ', scores)\n",
    "        print(str(step) + '-Ahead ROC score: ', roc_auc_score(y_test, rf_model.predict_proba(x_test), multi_class='ovr'))\n",
    "\n",
    "        # plot\n",
    "        plt.plot(y_test, 'o', color='orange', label = \"Actual\")\n",
    "        plt.plot(rf_predictions,  'x', color='blue', label = \"Prediction\")\n",
    "        plt.title(str(step) + '-Ahead Prediction')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        future_x = data[data.index == '2021-07-28']\n",
    "        future_x = future_x.dropna(axis = 'columns')\n",
    "        future_x = future_x[feature_columns]\n",
    "\n",
    "        prediction = rf_model.predict(np.array(future_x))\n",
    "        prediction = int(prediction)\n",
    "        \n",
    "        future_pred.append(prediction)\n",
    "       \n",
    "    return future_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = list(range(1,13))\n",
    "multi_step_pred('RateDecision', n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pred = pd.Series(future_pred)\n",
    "future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffr_data = data['RateDecision']\n",
    "ffr_data = ffr_data.append((future_predictions))\n",
    "ffr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffr_data.to_csv('../data/fed_funds_predictions.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
